import os
from pathlib import Path
import sys  
ROOT_PATH = Path(__file__).parent.parent.parent
sys.path.append(os.path.join(ROOT_PATH, ''))
from datetime import date
import ntpath

from python.example_schema.dataset_example import Dataset 
from python.util import utils, config
from python.util.logger_factory import logger


# THIS SCRIPT DEAGGREGATES ENTIRE ROWS OF DATA THAT CONTAIN ROLLED UP DATA
# RUN SCRIPT deagg.py BEFORE THIS ONE TO DEAGGREGATE THE LOOKUP VALUES THEMSELVES. 
ust_or_release = 'ust' 			# Valid values are 'ust' or 'release'
control_id = 1                 # Enter an integer that is the ust_control_id or release_control_id
data_table_name = 'Tanks' 			# Enter a string containing organization table name that contains the aggregated data 
data_table_pk_cols = ['Facility Id','Tank Name'] 		# Python list of column names FROM THE SOURCE DATA that the new table should be grouped by, for example, in UST, substances may be grouped by ['FacilityID','TankID'] or ['FacilityID','TankID','CompartmentID'] 
data_deagg_column_name = 'Tank Substance' 	# Column name FROM THE SOURCE DATA that contains the aggregated values 
delimiter = ', ' 				# Defaults to ', '; delimiter from the column beging deaggregated in the source table. Use '\n' for hard returns.
deagg_table_name = 'erg_tank_substance_deagg'           # Deagg table name generated by deagg_example.py. It will begin with an 'erg_' prefix. Check column deagg_table_name in table ust_element_mapping or release_element_mapping if you don't know it. (deagg_example.py will set this value.)
drop_existing = False 			# Boolean, defaults to False. Set to True to drop the _datarows_deagg table that this script creates before beginning (for example, if you need to rerun this script)


class deaggRows:
	conn = None  
	cur = None  

	def __init__(self, 
				 dataset,
				 data_table_name,
				 data_table_pk_cols,
				 data_deagg_column_name,
				 delimiter,
				 deagg_table_name,
				 drop_existing=False):
		self.dataset = dataset
		self.data_table_name = data_table_name
		self.data_table_pk_cols = data_table_pk_cols
		self.data_deagg_column_name = data_deagg_column_name
		self.delimiter = delimiter
		self.deagg_table_name = deagg_table_name
		self.drop_existing = drop_existing
		self.data_deagg_table_name = utils.get_deagg_datarows_table_name(self.deagg_table_name)
		self.epa_table_name = self.deagg_table_name.replace('erg', self.dataset.ust_or_release).replace('_deagg','')
		self.element_mapping_table = self.dataset.ust_or_release + '_element_mapping'
		self.set_db_connection()
		# self.create_deagg_rows_table()
		self.update_element_mapping()
		self.disconnect_db()


	def set_db_connection(self):
		self.conn = utils.connect_db()
		self.cur = self.conn.cursor()


	def disconnect_db(self):
		self.conn.commit()
		self.cur.close()
		self.conn.close()


	def create_deagg_rows_table(self):
		sql = "select count(*) from information_schema.tables where table_schema = %s and table_name = %s"
		self.cur.execute(sql, (self.dataset.schema, self.data_deagg_table_name))
		cnt = self.cur.fetchone()[0]
		if cnt > 0:
			if self.drop_existing:
				sql2 = f'drop table {self.dataset.schema}."{self.data_deagg_table_name}"'
				self.cur.execute(sql2)
			else:
				logger.warning('Table %s.%s already exists but drop_existing flag is False. Set drop_existing to True to continue. Exiting...', self.dataset.schema, self.data_deagg_table_name)
				exit()

		# convert list of columns into a string and wrap each one in quotes 
		col_str = ''  
		for col in data_table_pk_cols:
			col_str = col_str + '"' + col + '",' 
		
		# create _datarows_deagg table with empty column for deagged values 
		sql = f"""select {col_str} cast(null as varchar(400)) as "{self.data_deagg_column_name}" 
		          into {self.dataset.schema}."{self.data_deagg_table_name}" 
		          from {self.dataset.schema}."{self.data_table_name}" where 1=2""" 
		self.cur.execute(sql)

		sql = f"""select distinct {col_str} "{self.data_deagg_column_name}" 
		          from {self.dataset.schema}."{self.data_table_name}" 
                  where "{self.data_deagg_column_name}" is not null
                  order by 1, 2""" 
		self.cur.execute(sql)
		rows = self.cur.fetchall()
		for row in rows: 
			i = len(row)-1
			col_text = row[i]
			try:
				parts = col_text.split(self.delimiter)
			except AttributeError:
				parts = [None]
			for part in parts:
				# TODO: make this dynamic
				if i == 1:
					sql2 = f"""insert into {self.dataset.schema}.{self.data_deagg_table_name} ({col_str} "{self.data_deagg_column_name}") 
					           values (%s, %s)"""
					self.cur.execute(sql2, (row[0], part))
					logger.info('Inserted %s, %s into %s.%s', row[0], part, self.dataset.schema, self.data_deagg_table_name)
				elif i == 2:
					sql2 = f"""insert into {self.dataset.schema}.{self.data_deagg_table_name} ({col_str} "{self.data_deagg_column_name}") 
					           values (%s, %s, %s)"""
					self.cur.execute(sql2, (row[0], row[1], part))
					logger.info('Inserted %s, %s, %s into %s.%s', row[0], row[1], part, self.dataset.schema, self.data_deagg_table_name)
				elif i == 3:
					sql2 = f"""insert into {self.dataset.schema}.{self.data_deagg_table_name} ({col_str} "{self.data_deagg_column_name}") 
					           values (%s, %s, %s, %s)"""
					self.cur.execute(sql2, (row[0], row[1], row[2], part))
					logger.info('Inserted %s, %s, %s, %s into %s.%s', row[0], row[1], row[2], part, self.dataset.schema, self.data_deagg_table_name)
				elif i == 4:
					sql2 = f"""insert into {self.dataset.schema}.{self.data_deagg_table_name} ({col_str} "{self.data_deagg_column_name}") 
					           values (%s, %s, %s, %s, %s)"""
					self.cur.execute(sql2, (row[0], row[1], row[2], row[3], part))
					logger.info('Inserted %s, %s, %s, %s, %s into %s.%s', row[0], row[1], row[2], row[3], part, self.dataset.schema, self.data_deagg_table_name)
				elif i == 5:
					sql2 = f"""insert into {self.dataset.schema}.{self.data_deagg_table_name} ({col_str} "{self.data_deagg_column_name}") 
					           values (%s, %s, %s, %s, %s, %s)"""
					self.cur.execute(sql2, (row[0], row[1], row[2], row[3], row[4], part))
					logger.info('Inserted %s, %s, %s, %s, %s, %s into %s.%s', row[0], row[1], row[2], row[3], row[4], part, self.dataset.schema, self.data_deagg_table_name)
				elif i == 6:
					sql2 = f"""insert into {self.dataset.schema}.{self.data_deagg_table_name} ({col_str} "{self.data_deagg_column_name}") 
					           values (%s, %s, %s, %s, %s, %s, %s)"""
					self.cur.execute(sql2, (row[0], row[1], row[2], row[3], row[4], row[5], part))
					logger.info('Inserted %s, %s, %s, %s, %s, %s, %s into %s.%s', row[0], row[1], row[2], row[3], row[4], row[5], part, self.dataset.schema, self.data_deagg_table_name)
				else:
					logger.critical('There are more grouped by/pk columns (%s) in data_table_pk_cols (%s) than this script has been coded to handle. Update the loop that does the deagg.', i, self.data_table_pk_cols)
			self.conn.commit()
		logger.info('Finished deagging %s."%s"."%s" into %s', self.dataset.schema, self.data_table_name, self.data_deagg_column_name, self.data_deagg_table_name)


	def update_element_mapping(self):
		logger.info('Updating %s for %s', self.element_mapping_table, self.deagg_table_name)
		sql = f"""update example.{self.element_mapping_table} 
				  set deagg_table_name = %s, organization_join_table = %s """
		i = 1
		for pk_col in self.data_table_pk_cols:
				if i == 1:
					join_col_name = 'organization_join_column'
					fk_col_name = 'organization_join_fk'
				else:
					join_col_name = 'organization_join_column' + str(i)
					fk_col_name = 'organization_join_fk' + str(i)					
				sql = sql + f", {join_col_name} = '{pk_col}', {fk_col_name} = '{pk_col}'" 
				i += 1
		sql = sql + f""" where {self.dataset.ust_or_release}_control_id = %s and deagg_table_name = %s"""
		self.cur.execute(sql, (self.data_deagg_table_name, self.data_table_name, self.dataset.control_id, self.deagg_table_name))
		self.conn.commit()
		logger.info('Updated element mapping for %s in %s', self.data_deagg_table_name, self.element_mapping_table)


def main(ust_or_release,
		 control_id, 
	     data_table_name, 
	     data_table_pk_cols,
	     data_deagg_column_name,
	     deagg_table_name,
	     delimiter,
	     drop_existing
	     ):
	dataset = Dataset(ust_or_release=ust_or_release,
				 	  control_id=control_id,
					  requires_export=False)
	drows = deaggRows(dataset=dataset, 
					 data_table_name=data_table_name, 
					 data_table_pk_cols=data_table_pk_cols,
					 data_deagg_column_name=data_deagg_column_name,
					 deagg_table_name=deagg_table_name,
					 delimiter=delimiter,
					 drop_existing=drop_existing)


if __name__ == '__main__':   
	main(ust_or_release=ust_or_release, 
		 control_id=control_id,
		 data_table_name=data_table_name, 
		 data_table_pk_cols=data_table_pk_cols,
		 data_deagg_column_name=data_deagg_column_name,
		 deagg_table_name=deagg_table_name,
		 delimiter=delimiter,
		 drop_existing=drop_existing)
